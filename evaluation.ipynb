{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1Qw6tKJ0gBjm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import Adam\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, average_precision_score\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report,matthews_corrcoef,f1_score\n",
        "\n",
        "USE_CUDA = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy"
      ],
      "metadata": {
        "id": "kEgnDnt6zBEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HJkdRTMZgBjp"
      },
      "outputs": [],
      "source": [
        "class ConvLayer(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=256, kernel_size=9):\n",
        "        super(ConvLayer, self).__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=in_channels,\n",
        "                               out_channels=out_channels,\n",
        "                               kernel_size=kernel_size,\n",
        "                               stride=1\n",
        "                             )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.relu(self.conv(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1JFz-PL8gBjp"
      },
      "outputs": [],
      "source": [
        "class PrimaryCaps(nn.Module):\n",
        "    def __init__(self, num_capsules=8, in_channels=256, out_channels=8, kernel_size=9):\n",
        "        super(PrimaryCaps, self).__init__()\n",
        "\n",
        "        self.capsules = nn.ModuleList([\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=2, padding=0)\n",
        "                          for _ in range(num_capsules)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        u = [capsule(x) for capsule in self.capsules]\n",
        "        u = torch.stack(u, dim=1)\n",
        "        u = u.view(x.size(0), 8*24*24 , -1)\n",
        "        return self.squash(u)\n",
        "\n",
        "    def squash(self, input_tensor):\n",
        "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
        "        output_tensor = squared_norm *  input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
        "        return output_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-r1eiL5tgBjq"
      },
      "outputs": [],
      "source": [
        "class DigitCaps(nn.Module):\n",
        "    def __init__(self, num_capsules=2, num_routes=8*24*24, in_channels=8, out_channels=32):\n",
        "        super(DigitCaps, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.num_routes = num_routes\n",
        "        self.num_capsules = num_capsules\n",
        "\n",
        "        self.W = nn.Parameter(torch.randn(1, num_routes, num_capsules, out_channels, in_channels))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = torch.stack([x] * self.num_capsules, dim=2).unsqueeze(4)\n",
        "        W = torch.cat([self.W] * batch_size, dim=0)\n",
        "        u_hat = torch.matmul(W, x)\n",
        "\n",
        "        b_ij = Variable(torch.zeros(1, self.num_routes, self.num_capsules, 1))\n",
        "        if USE_CUDA:\n",
        "            b_ij = b_ij.cuda()\n",
        "\n",
        "        num_iterations = 3\n",
        "        for iteration in range(num_iterations):\n",
        "            c_ij = F.softmax(b_ij)\n",
        "            c_ij = torch.cat([c_ij] * batch_size, dim=0).unsqueeze(4)\n",
        "\n",
        "            s_j = (c_ij * u_hat).sum(dim=1, keepdim=True)\n",
        "            v_j = self.squash(s_j)\n",
        "\n",
        "            if iteration < num_iterations - 1:\n",
        "                a_ij = torch.matmul(u_hat.transpose(3, 4), torch.cat([v_j] * self.num_routes, dim=1))\n",
        "                b_ij = b_ij + a_ij.squeeze(4).mean(dim=0, keepdim=True)\n",
        "\n",
        "        return v_j.squeeze(1)\n",
        "\n",
        "    def squash(self, input_tensor):\n",
        "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
        "        output_tensor = squared_norm *  input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
        "        return output_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GA4lZTIpgBjq"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.reconstraction_layers = nn.Sequential(\n",
        "            nn.Linear(32 * 2, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 1*64*64),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, data):\n",
        "        classes = torch.sqrt((x ** 2).sum(2))\n",
        "        classes = F.softmax(classes,dim=1)\n",
        "\n",
        "        _, max_length_indices = classes.max(dim=1)\n",
        "        masked = Variable(torch.sparse.torch.eye(2))\n",
        "        if USE_CUDA:\n",
        "            masked = masked.cuda()\n",
        "        masked = masked.index_select(dim=0, index=max_length_indices.squeeze(1).data)\n",
        "\n",
        "        reconstructions = self.reconstraction_layers((x * masked[:, :, None, None]).view(x.size(0), -1))\n",
        "        reconstructions = reconstructions.view(-1, 1, 64, 64)\n",
        "\n",
        "        return reconstructions, masked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TI19KvcegBjr"
      },
      "outputs": [],
      "source": [
        "class CapsNet(nn.Module):\n",
        "    def __init__(self,Primary_capsule_num=8):\n",
        "        super(CapsNet, self).__init__()\n",
        "        self.conv_layer = ConvLayer()\n",
        "        self.primary_capsules = PrimaryCaps(num_capsules=Primary_capsule_num)\n",
        "        self.digit_capsules = DigitCaps(in_channels=Primary_capsule_num)\n",
        "        self.decoder = Decoder()\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "\n",
        "    def forward(self, data):\n",
        "        output = self.digit_capsules(self.primary_capsules(self.conv_layer(data)))\n",
        "        reconstructions, masked = self.decoder(output, data)\n",
        "        print(output.size())\n",
        "        return output, reconstructions, masked\n",
        "\n",
        "    def loss(self, data, x, target, reconstructions):\n",
        "        return self.margin_loss(x, target) + self.reconstruction_loss(data, reconstructions)\n",
        "\n",
        "    def margin_loss(self, x, labels, size_average=True):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        v_c = torch.sqrt((x**2).sum(dim=2, keepdim=True))\n",
        "\n",
        "        left = F.relu(0.9 - v_c).view(batch_size, -1)\n",
        "        right = F.relu(v_c - 0.1).view(batch_size, -1)\n",
        "        loss = labels * left + 0.5 * (1.0 - labels) * right\n",
        "        loss = loss.sum(dim=1).mean()\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def reconstruction_loss(self, data, reconstructions):\n",
        "        loss = self.mse_loss(reconstructions.view(reconstructions.size(0), -1), data.view(reconstructions.size(0), -1))\n",
        "        return loss * 0.0005"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhYvCErEu013"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "batch_size = 64\n",
        "n_epochs = 20\n",
        "res = 64\n",
        "\n",
        "fig_test = pd.read_csv(\"test.txt\")\n",
        "y_test=fig_test['label']\n",
        "y_test\n",
        "str_list_test=[]\n",
        "for i in fig_test['figure']:\n",
        "  temp=np.array(i.split(\" \"),dtype=np.float32).reshape(res,res)\n",
        "  str_list_test.append(temp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thaXD4m_zozA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4a038f6-f620-4218-be37-1ba798346976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-39fd547b6980>:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  X_test=torch.tensor(str_list_test)\n"
          ]
        }
      ],
      "source": [
        "X_test=torch.tensor(str_list_test)\n",
        "X_test=X_test.unsqueeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vytJMuGfoTza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3Z8pPSHu42I"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "test_dataset=TensorDataset(X_test,torch.tensor(y_test))\n",
        "test_loader=DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuQW3m0a18rj"
      },
      "outputs": [],
      "source": [
        "# X.size()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# num_cap_list=[8]"
      ],
      "metadata": {
        "id": "tHaNq73-VDdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PYgauJu7mlYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_cap = torch.load('capsule_net.pth').to(\"cuda\")\n",
        "\n",
        "test_dataset = TensorDataset(X_test,torch.tensor(y_test))\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "with torch.no_grad():\n",
        "    all_pred = []\n",
        "    all_score = []\n",
        "    all_prob=[]\n",
        "    all_type=[]\n",
        "    for step, (batch_x, batch_y) in enumerate(test_loader):\n",
        "        output, reconstructions, masked = model_cap(batch_x.to(\"cuda\"))\n",
        "        pred_labels = np.argmax(masked.data.cpu().numpy(), 1)\n",
        "        pred  = np.argmax(masked.cpu().detach().numpy(),axis=1).tolist()\n",
        "        classes = torch.sqrt((output ** 2).sum(2))\n",
        "        classes = F.softmax(classes,dim=1).detach().cpu().numpy().tolist()\n",
        "        all_prob += classes\n",
        "        all_pred += pred\n",
        "        all_type += output.reshape(-1,64)\n",
        "\n",
        "\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, all_pred).ravel()\n",
        "    perftab = {\"CM\": confusion_matrix(y_test, all_pred),\n",
        "            'ACC': (tp + tn) / (tp + fp + fn + tn),\n",
        "            'SEN': tp / (tp + fn),\n",
        "            'PREC': tp / (tp + fp),\n",
        "            \"SPEC\": tn / (tn + fp),\n",
        "            \"MCC\": matthews_corrcoef(y_test, all_pred),\n",
        "            \"F1\": f1_score(y_test, all_pred)\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZVF-rd2PISE",
        "outputId": "c7855e33-84ab-408f-cc0c-fcf4a0446bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-219208592d22>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_cap = torch.load('capsule_net.pth').to(\"cuda\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([64, 2, 32, 1])\n",
            "torch.Size([18, 2, 32, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perftab"
      ],
      "metadata": {
        "id": "Gz3xleoivfqK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "937ece43-0d41-4072-c4e0-108638dad601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CM': array([[1043,   54],\n",
              "        [  20, 1077]]),\n",
              " 'ACC': 0.9662716499544212,\n",
              " 'SEN': 0.9817684594348223,\n",
              " 'PREC': 0.9522546419098143,\n",
              " 'SPEC': 0.95077484047402,\n",
              " 'MCC': 0.9329915254664284,\n",
              " 'F1': 0.9667863554757631}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# score_result=score_result.squeeze()"
      ],
      "metadata": {
        "id": "88Wl40MJx9rI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
